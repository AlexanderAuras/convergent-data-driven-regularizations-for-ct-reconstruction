{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt\n",
    "from typing import cast\n",
    "\n",
    "import radon\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from lodopab_dataset import LoDoPaBDataset\n",
    "from lodopab2_dataset import LoDoPaB2Dataset\n",
    "from ellipses2_dataset import Ellipses2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "angles = torch.linspace(0.0, torch.pi, 257)[:-1]\n",
    "positions = torch.arange(-ceil(img_size*1.41421356237/2.0), ceil(img_size*1.41421356237/2.0)+1, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af74b27d5b734659871b1b7c8f9fe933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289dab1034e941afbac08b4de424e6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e484da357941ed8c7cf3f9f35f48a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_count = sum(1 for _ in Path(\"/data/datasets/Ellipses/train\").iterdir())\n",
    "for path in tqdm.notebook.tqdm(Path(\"/data/datasets/Ellipses/train\").iterdir(), total=file_count):\n",
    "    if path.name.startswith(\"ground_truth_\"):\n",
    "        gt = torch.load(str(path.resolve())).contiguous()\n",
    "        torch.save(gt, f\"/data/datasets/Ellipses/train/ground_truth_{path.stem[13:]}.pt\")\n",
    "        sino = radon.radon_forward(gt.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "        torch.save(sino, f\"/data/datasets/Ellipses/train/sinogram_{path.stem[13:]}.pt\")\n",
    "\n",
    "file_count = sum(1 for _ in Path(\"/data/datasets/Ellipses/val\").iterdir())\n",
    "for path in tqdm.notebook.tqdm(Path(\"/data/datasets/Ellipses/val\").iterdir(), total=file_count):\n",
    "    if path.name.startswith(\"ground_truth_\"):\n",
    "        gt = torch.load(str(path.resolve())).contiguous()\n",
    "        torch.save(gt, f\"/data/datasets/Ellipses/val/ground_truth_{path.stem[13:]}.pt\")\n",
    "        sino = radon.radon_forward(gt.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "        torch.save(sino, f\"/data/datasets/Ellipses/val/sinogram_{path.stem[13:]}.pt\")\n",
    "\n",
    "file_count = sum(1 for _ in Path(\"/data/datasets/Ellipses/test\").iterdir())\n",
    "for path in tqdm.notebook.tqdm(Path(\"/data/datasets/Ellipses/test\").iterdir(), total=file_count):\n",
    "    if path.name.startswith(\"ground_truth_\"):\n",
    "        gt = torch.load(str(path.resolve())).contiguous()\n",
    "        torch.save(gt, f\"/data/datasets/Ellipses/test/ground_truth_{path.stem[13:]}.pt\")\n",
    "        sino = radon.radon_forward(gt.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "        torch.save(sino, f\"/data/datasets/Ellipses/test/sinogram_{path.stem[13:]}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(img_size, antialias=cast(str, True)),\n",
    "    torchvision.transforms.CenterCrop(img_size)\n",
    "])\n",
    "\n",
    "\n",
    "dataset = LoDoPaBDataset(\"/data/datasets\", LoDoPaBDataset.Subset.TRAIN, extracted=True)\n",
    "for i, sample in tqdm.notebook.tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    ground_truth = transform(sample[1])\n",
    "    sinogram = radon.radon_forward(ground_truth.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "    torch.save(ground_truth, f\"/data/datasets/LoDoPaB2/train/ground_truth_{i}.pt\")\n",
    "    torch.save(sinogram, f\"/data/datasets/LoDoPaB2/train/sinogram_{i}.pt\")\n",
    "    if i == len(dataset)-1:\n",
    "        break\n",
    "\n",
    "dataset = LoDoPaBDataset(\"/data/datasets\", LoDoPaBDataset.Subset.VAL, extracted=True)\n",
    "for i, sample in tqdm.notebook.tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    ground_truth = transform(sample[1])\n",
    "    sinogram = radon.radon_forward(ground_truth.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "    torch.save(ground_truth, f\"/data/datasets/LoDoPaB2/val/ground_truth_{i}.pt\")\n",
    "    torch.save(sinogram, f\"/data/datasets/LoDoPaB2/val/sinogram_{i}.pt\")\n",
    "    if i == len(dataset)-1:\n",
    "        break\n",
    "\n",
    "dataset = LoDoPaBDataset(\"/data/datasets\", LoDoPaBDataset.Subset.TEST, extracted=True)\n",
    "for i, sample in tqdm.notebook.tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    ground_truth = transform(sample[1])\n",
    "    sinogram = radon.radon_forward(ground_truth.unsqueeze(0).to(\"cuda\"), angles.to(\"cuda\"), positions.to(\"cuda\"))[0].to(\"cpu\")\n",
    "    torch.save(ground_truth, f\"/data/datasets/LoDoPaB2/test/ground_truth_{i}.pt\")\n",
    "    torch.save(sinogram, f\"/data/datasets/LoDoPaB2/test/sinogram_{i}.pt\")\n",
    "    if i == len(dataset)-1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = radon.radon_matrix(torch.zeros(img_size, img_size, device=\"cuda\"), thetas=angles.to(\"cuda\"), positions=positions.to(\"cuda\"))\n",
    "v, d, ut = torch.linalg.svd(matrix, full_matrices=False)\n",
    "torch.save(v.mT.to(\"cpu\"), \"/home/alexander/Projects/convergent-data-driven-regularizations-for-ct-reconstruction/cache/vt.pt\")\n",
    "torch.save(d.to(\"cpu\"), \"/home/alexander/Projects/convergent-data-driven-regularizations-for-ct-reconstruction/cache/d.pt\")\n",
    "torch.save(ut.mT.to(\"cpu\"), \"/home/alexander/Projects/convergent-data-driven-regularizations-for-ct-reconstruction/cache/u.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnl-alpha: 0.0   gnl-loss: 1.673e-11 / 0.000e+00\n"
     ]
    }
   ],
   "source": [
    "sample = Ellipses2Dataset(\"/data/datasets\", Ellipses2Dataset.Subset.TEST)[0]\n",
    "gt_e = sample[1].to(\"cuda\")\n",
    "\n",
    "sino_gne = sample[0].to(\"cuda\")                                                              #gne:  0.0\n",
    "sino_gle = sino_gne+0.005*torch.randn_like(sino_gne)                                         #gle:  0.014\n",
    "sino_gme = sino_gne+0.015*torch.randn_like(sino_gne)                                         #gme:  0.046\n",
    "sino_ghe = sino_gne+0.03*torch.randn_like(sino_gne)                                          #ghe:  0.095\n",
    "\n",
    "sino_une = Ellipses2Dataset(\"/data/datasets\", Ellipses2Dataset.Subset.TEST)[0][0].to(\"cuda\") #une:  0.0\n",
    "sino_ule = sino_une-sqrt(3.0)*0.005+2.0*sqrt(3.0)*0.005*torch.rand_like(sino_une)            #ule:  0.0148\n",
    "sino_ume = sino_une-sqrt(3.0)*0.015+2.0*sqrt(3.0)*0.015*torch.rand_like(sino_une)            #ume:  0.047\n",
    "sino_uhe = sino_une-sqrt(3.0)*0.03+2.0*sqrt(3.0)*0.03*torch.rand_like(sino_une)              #uhe:  0.095\n",
    "\n",
    "sample = LoDoPaB2Dataset(\"/data/datasets\", LoDoPaB2Dataset.Subset.TEST)[0]\n",
    "gt_l = sample[1].to(\"cuda\")\n",
    "sino_gnl = sample[0].to(\"cuda\")                                                              #gnl:  0.0\n",
    "sino_gll = sino_gnl+0.005*torch.randn_like(sino_gnl)                                         #gll:  0.0288\n",
    "sino_gml = sino_gnl+0.015*torch.randn_like(sino_gnl)                                         #gml:  0.079\n",
    "sino_ghl = sino_gnl+0.03*torch.randn_like(sino_gnl)                                          #ghl:  0.13\n",
    "\n",
    "sino_unl = LoDoPaB2Dataset(\"/data/datasets\", LoDoPaB2Dataset.Subset.TEST)[0][0].to(\"cuda\")   #unl:  0.0\n",
    "sino_ull = sino_unl-sqrt(3.0)*0.005+2.0*sqrt(3.0)*0.005*torch.rand_like(sino_unl)            #ull:  0.028\n",
    "sino_uml = sino_unl-sqrt(3.0)*0.015+2.0*sqrt(3.0)*0.015*torch.rand_like(sino_unl)            #uml:  0.074\n",
    "sino_uhl = sino_unl-sqrt(3.0)*0.03+2.0*sqrt(3.0)*0.03*torch.rand_like(sino_unl)              #uhl:  0.15\n",
    "\n",
    "sino_gxe = sino_gne+0.01*torch.randn_like(sino_gne)                                          #gxe:  0.03\n",
    "sino_uxe = sino_une+0.01*torch.randn_like(sino_une)                                          #uxe:  0.033\n",
    "sino_gxl = sino_gnl+0.01*torch.randn_like(sino_gnl)                                          #gxl:  0.055\n",
    "sino_uxl = sino_unl+0.01*torch.randn_like(sino_unl)                                          #uxl:  0.055\n",
    "\n",
    "\n",
    "for short in [\"gxe\",\"uxe\",\"gne\",\"gle\",\"gme\",\"ghe\",\"une\",\"ule\",\"ume\",\"uhe\",\"gnl\",\"gll\",\"gml\",\"ghl\",\"unl\",\"ull\",\"uml\",\"uhl\",\"gxl\",\"uxl\"]:\n",
    "    alpha = 0.0\n",
    "\n",
    "    while True:\n",
    "        in_ = input(short+\"-alpha: \")\n",
    "        if in_ == \"q\":\n",
    "            break\n",
    "        else:\n",
    "            alpha = float(in_)\n",
    "\n",
    "        A_ = radon.radon_matrix(torch.zeros(img_size, img_size, device=\"cuda\"), thetas=angles.to(\"cuda\"), positions=positions.to(\"cuda\"))\n",
    "        alphaI = alpha*torch.eye(A_.shape[1], device=\"cuda\")\n",
    "        ATA = A_.mT@A_\n",
    "        A = ATA + alphaI\n",
    "\n",
    "        sino = globals()[\"sino_\"+short]\n",
    "        b = radon.radon_backward(sino.unsqueeze(0), img_size, angles.to(\"cuda\"), positions.to(\"cuda\"))[0]\n",
    "        b = b.reshape(*b.shape[:-2], -1, 1)\n",
    "        z = torch.linalg.solve(A, b)\n",
    "        recon = z.reshape(sino.shape[0], 1, img_size, img_size)\n",
    "        recon_sino = radon.radon_forward(recon, thetas=angles.to(\"cuda\"), positions=positions.to(\"cuda\"))[0]\n",
    "        loss = torch.nn.functional.mse_loss(recon_sino, sino)\n",
    "        lvl = {\"n\": 0.0, \"l\": 0.005, \"m\": 0.015, \"h\": 0.03, \"x\": 0.01}[short[1]]\n",
    "        print(f\"{short}-alpha: {alpha}   {short}-loss: {loss.item():5.3e} / {lvl**2:5.3e}\", flush=True)\n",
    "\n",
    "    torch.save(A, f\"/home/alexander/Projects/convergent-data-driven-regularizations-for-ct-reconstruction/cache/A_{short}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = radon.radon_matrix(torch.zeros(img_size, img_size, device=\"cuda\"), thetas=angles.to(\"cuda\"), positions=positions.to(\"cuda\"))\n",
    "torch.save(A.mT@A, f\"/home/alexander/Projects/convergent-data-driven-regularizations-for-ct-reconstruction/cache/A.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FSDLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
